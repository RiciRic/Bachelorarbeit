\chapter{Einleitung}
\label{chap:einleitung}
In einer globalisierten und dynamischen Wirtschaftswelt sind Unternehmen zunehmend auf Projekte angewiesen, um ihre Ziele zu erreichen und Wettbewerbsvorteile zu erlangen. Die Personalbeschaffung für solche Projekte erfordert oft spezialisiertes Fachwissen und vielfältige Fähigkeiten, um erfolgreich umgesetzt zu werden. Es ist entscheidend für den Projekterfolg, dass die Personalbeschaffung die passenden Mitarbeiter für ausgewählte Projekte findet. Hier setzt die Entwicklung eines Recommender Systems zur Mitarbeiterempfehlung an. Ein solches System kann Unternehmen dabei unterstützen, den Prozess der Mitarbeiterrekrutierung und -auswahl zu optimieren. Durch die Berücksichtigung verschiedener Kriterien wie Qualifikationen, Fähigkeiten und Erfahrungen kann das Recommender-System dazu beitragen, die Auswahl effektiv zu filtern und diejenigen herauszufiltern, die am besten zu einem Projekt im Unternehmen passen. Ein solches System bietet außerdem den Vorteil, den Prozess der Mitarbeiterempfehlung zu automatisieren und zu beschleunigen. Dies ermöglicht Unternehmen, schneller auf offene Stellen zu reagieren und potenzielle Kandidaten zeitnah zu identifizieren. Dadurch wird die Effizienz der Mitarbeitersuche verbessert und die Qualität der Einstellungsentscheidungen erhöht.\\

Das Potenzial von Recommender Systems wurde auch bei \emph{adesso} entdeckt und nun wird nach und nach Wege gesucht, KI-gestützte Systeme in die eigenen Prozesse zu integrieren. Im internen Projekt \emph{adesso Staffing Advisor} wird an einem Recommender-System zur Mitarbeiterempfehlung für ausgewählte Projekte gearbeitet. Die Umsetzung der Recommender Systems bedient sich verschiedener KI-basierten Ansätze. Ein ganz entscheidender Schritt im Prozess der Mitarbeiterempfehlung ist die Vorverarbeitung der \emph{Bedarfsmeldungen}. Diese sind eine wertvolle Informationsquelle, die Führungskräften helfen kann, die Empfehlungen effizienter zu gestalten, um dadurch wettbewerbsfähig zu bleiben. Allerdings sind diese oft umfangreich, unsortiert und komplex, was ihre effektive Nutzung erschwert. Deshalb ist es entscheidend, effiziente Methoden und Techniken des Information Retrieval anzuwenden, um so relevante Informationen schnell und präzise aus \emph{Bedarfsmeldungen} zu extrahieren. Die Extraktion wichtiger Schlüsselwörter, Phrasen und Themen ermöglicht es einen besseren Einblick in die Ziele, Methoden und Ergebnisse der Projekte zu bekommen. Dadurch können fundierte Entscheidungen bezüglich der Personalbesetzung getroffen und Ressourcen effizient genutzt werden.\\
\section{Problemstellung}
\label{sec:problemstellung}
Um das Entlastungspotenzial für Führungskräfte durch das Gesamtsystem eines Recommender Systems für Mitarbeiterempfehlungen zu realisieren, sind mehrere Schritte notwendig. Eine Informationsgewinnung aus den unstrukturierten Projekt- und Mitarbeiterdaten ist unerlässlich, um schließlich den Ähnlichkeitsvergleich für die Empfehlungen durchführen zu können. Diese Ausarbeitung befasst sich mit dem ersten Schritt der Strukturierung und Informationsextraktion der vorhandenen \emph{Bedarfsmeldungen}. Somit steht \emph{adesso} vor der Herausforderung, relevante Informationen effizient aus umfangreichen \emph{Bedarfsmeldungen} zu extrahieren. Obwohl diese Beschreibungen wichtige Einblicke in Ziele, Methoden und Ergebnisse liefern, können sie aufgrund ihres Umfangs und ihrer Komplexität schwer durchsuchbar und analysierbar sein. Die manuelle Identifizierung und Extraktion relevanter Inhalte ist zeitaufwendig und fehleranfällig. Daher stellt sich die Problemstellung: \\

Wie können wir effektive Methoden und Techniken des Information Retrieval und Data-Mining nutzen, um automatisiert relevante Inhalte aus \emph{Bedarfsmeldungen} im spezifischen Software Entwicklungs-Kontext zu extrahieren und somit die Effizienz, Genauigkeit und Geschwindigkeit der Informationsgewinnung für Führungskräfte zu verbessern.\\

In der Vergangenheit wurden bereits Methoden im Bereich des automatisierten Recruitings untersucht. Im Projektgeschäft sehen wir uns mit einem Problem konfrontiert, dessen Umfang jedoch präziser definiert werden kann, da die Kandidatenauswahl einem begrenzten Pool unterliegt. Besondere Relevanz hat hierbei die Erstellung einer Standardisierung der \emph{Bedarfsmeldung}, da diese häufig unstrukturiert und mit fehlenden Informationen vorliegt.
\section{Ziele und Ergebnisse der Arbeit}
\label{sec:zieleundergebnis}
Diese Ausarbeitung präsentiert eine umfassende Untersuchung zur Entwicklung eines automatisierten Systems zur Extraktion relevanter Inhalte aus \emph{Bedarfsmeldungen} im Software-Entwicklungs-Kontext.
\begin{itemize}
	\item In der Ausarbeitung wird zunächst ein Konzept einer standardisierten \emph{Bedarfsmeldung} erarbeitet. Dazu wird eine klare Erwartungshaltung hinsichtlich der Anforderungen und Bedürfnisse der Stakeholder entwickeln. Hierfür werden Interviews mit Führungskräften durchgeführt, um die Erwartungen bezüglich einer \glqq{}perfekten\grqq{} \emph{Bedarfsmeldung} herauszuarbeiten. Dieses Konzept dient als Grundlage für die weiteren Entwicklungs- und Evaluierungsphasen.
	\item Es wird an einer ausführbaren prototypischen Software gearbeitet, die \emph{Bedarfsmeldungen} effizient verarbeitet und wichtige Informationen extrahiert. Hierfür wird eine Pipeline in Python aufgebaut und strukturell durch Use-Case- und UML-Diagramme dokumentiert. Es werden Modelle des Information Retrieval und Data-Mining implementiert. Dabei erfolgt zunächst eine eingehende Analyse der Techniken \emph{TF-IDF}, \emph{Text-Ranking-Algorithmen}, \emph{N-Gramm-Analyse}, \emph{POS-Tagging}, \emph{Named Entity Recognition}, Regelbasierte Ansätze und Hybride Ansätze, um die besten Ansätze zur Extraktion relevanter Inhalte zu identifizieren. Diese Analyse bildet die Grundlage für die Konzeptionierung des Software-Prototypen, das eine Kombination der erforschten Ergebnisse darstellt.
	\item Um die Leistungsfähigkeit des entwickelten Systems zu evaluieren, werden Testfälle für reale \emph{Bedarfsmeldungen} definiert. Dabei wird überprüft, inwieweit das Ergebnis den Erwartungen entspricht. Mit Hilfe einer manuellen Überprüfung werden Abweichungen, Ähnlichkeiten und Anpassungen analysiert, um Erkenntnisse über die inhaltliche Leistung des Systems und die Techniken zu gewinnen, die allein oder in Kombination mit mehreren Ansätzen die wichtigsten Informationen herausfiltern. Da die Dauer eine entscheidende Rolle spielt, werden auch Zeit und Leistung gemessen. Diese Ergebnisse werden mit einem neuen Vorverarbeitungsansatz verglichen, der auf dem Large Language Model basiert. Die Performance, Zeit und Ergebnisqualität des entwickelten Systems soll im Vergleich mit diesem alternativen Ansatz die Stärken und Schwächen des entwickelten Systems aufzeigen, um daraus gegebenenfalls weitere Verbesserungsmöglichkeiten zu identifizieren.
\end{itemize}
\section{Aufbau der Arbeit}
\todo{Aufbau der Arbeit erstellen}
\newpage
g
\newpage
\chapter{Grundlagen}
\section{Kontext}
Als IT-Dienstleister wird adesso von Kunden unter anderem mit der Entwicklung individueller Softwarelösungen beauftragt. Derzeit verbringen Führungskräfte jedoch viel Zeit damit, interne Mitarbeiterinnen und Mitarbeiter manuell für Kundenprojekte zu suchen und diese dann aufgrund ihrer Erfahrungen und Fähigkeiten auszuwählen und entsprechend einzusetzen. Dieser Prozess soll durch eine KI-Lösung unterstützt werden. Da es sich bei der Personalsuche um einen geschäftskritischen Prozess handelt, ist der Spielraum für Fehler gering. Im internen Projekt adesso Staffing Advisor wird eine durch Large Language Model-gestützte Anwendung entwickelt, die Führungskräfte bei der Suche nach geeignetem Personal für ausgewählte Projekte unterstützt. Der Ansatz des Large Language Modeling ist jedoch nicht deterministisch. Es besteht die Gefahr, dass bei gleichem Input unterschiedliche Ergebnisse erzielt werden. Daher versucht adesso durch den Einsatz von Methoden und Technologien neben dem Large Language Model-Ansatz deterministische Ergebnisse zu erzielen, die auf einem ähnlichen Niveau liegen.\\

Die vorliegende Ausarbeitung befasst sich mit der Informationsgewinnung in Bedarfsmeldungen. Eine Bedarfsmeldung bezeichnet eine Projektbeschreibung eines Kunden, die Anforderungen an ein zu entwickelndes System enthält. Die Erstellung der Bedarfsmeldung erfolgt durch den Kunden, wobei eine gemeinsame Abstimmung mit adesso zur Finalisierung und Speicherung im JIRA erfolgt. Die Informationen sind insofern unstrukturiert, als dass sie ohne vordefinierte Struktur in Form eines Volltexts vorliegen. Infolgedessen kann es zu Abweichungen hinsichtlich der Ausgestaltung von Bedarfsmeldungen kommen.\\

\section{keine Ahnung}
Die Problemstellung umfasst eine Reihe von Punkten, die im Rahmen der Ausarbeitung zu behandeln sind. Aufgrund der unstrukturierten und mit fehlenden Informationen versehenen Bedarfsmeldungen ist eine Standardisierung dieser Bedarfsmeldungen von besonderer Relevanz. Dies würde die Extraktion relevanter Informationen erleichtern und somit die Effizienz des Systems verbessern. Zudem würde ein solcher Ansatz einen Einblick in die Relevanz von Informationen und Stichpunkten geben. Im Rahmen der weiteren Bearbeitung einer Standardisierung ist die Extraktion der erforderlichen Informationen aus dem Volltext erforderlich. In diesem Kontext existiert bereits eine Reihe an Methoden und Ansätzen, die sich in der Forschung bewährt haben. Der unstrukturierte Volltext muss in eine strukturierte inhaltliche Aufteilung in einzelne Sequenzen und Stichpunkte überführt werden.\\

In der Literatur finden sich verschiedene Ansätze zur Extraktion wichtiger Stichpunkte aus einem Volltext. Eine Methode zur Ermittlung wichtiger Stichpunkte in Texten stellt die \emph{tf-idf-Methode} (Term Frequency-Inverse Document Frequency) dar. Innerhalb einer oder mehrerer Bedarfsmeldungen lassen sich mit dieser Methode häufig auftauchende Wörter ermitteln. Des Weiteren können graphenbasierte Methoden wie \emph{TextRank} oder \emph{YAKE} (Yet Another Keyword Extractor) zur Identifizierung von Schlüsselwörtern in Texten herangezogen werden. Ein weiterer Ansatz ist die Nutzung von \emph{N-Grammen}, die häufig vorkommende Phrasen oder Begriffe identifizieren können. Auch grammatische Kategorien von Wörtern können Rückschlüsse auf potenzielle Schlüsselwörter zulassen. Die \emph{POS-Tagging}-Methode (Part-of-Speech-Tagging) stellt eine Möglichkeit dar, um dieses Ziel zu erreichen. Des Weiteren kann \emph{NER} (Named Entity Recognition) dazu beitragen, Personen, Firmennamen, Orte, Ereignisse oder Zeitangaben zu identifizieren. Auch wenn die Bedarfsmeldungen unstrukturiert sind, haben sich im Laufe der Zeit Konventionen entwickelt, die teilweise Strukturen eines \emph{Patterns} aufweisen können.