\chapter{Evaluierung}
\label{chap:evaluation}
Das vorliegende Kapitel befasst sich mit der Evaluierung des entwickelten Systems zur Strukturierung von \emph{Bedarfsmeldungen}. In dem Kapitel \ref{sec:literaturueberblick} wurde dargelegt, dass gängige Methoden zur Evaluierung von den einzelnen Information Retrieval Ansätzen und daraus entstehenden Pipelines und Hybriden die Methoden \emph{Precision, Recall} und \emph{F1-Score} angewendet werden. Grundsätzlich wäre dies ein valider Ansatz zur Evaluation. Dennoch bestehen keine Grundvoraussetzungen zur Durchführung dieser Methoden. Es liegt kein Datensatz mit ausreichenden Trainings und Testdaten vor. Die Erstellung eines Datensatzes auf Basis der originalen \emph{Bedarfsmeldungen} ist zeitaufwändig und erfordert Präzision. Dies ist im Rahmen der Ausarbeitung nicht weiter möglich. Stattdessen wird eine optimierende Evaluation auf Basis einer vordefinierten Erwartungshaltung durchgeführt, um Verbesserungspotenzial innerhalb des Systems zu ermitteln. Durch Modifikationen der Parameter der Pipeline wird versucht, eine vordefinierte Erwartungshaltung zu approximieren. Des Weiteren wird die Dauer der Prozessschritte dokumentiert, um die Durchführungszeit der Anpassungen zu erfassen.

%nicht überlegen wie evaluieren sonder was will ich evaluieren,\\
%was sind die fragen die ich beantworten möchte, was sind die aussagen die ich machen will. hypothesen belegen, wiederlegen\\

%z.b. erwartungshaltung formulieren und mit cosine similarity gucken was näher dran ist,

%wie machen das andere ansätze,

%-------------------

%-was genau will ich in die evaluation packen, was will ich da machen? (nehme den vergleich mit llm raus)

\section{Versuchsdurchführung}
Der nachfolgende Versuch dient der Überprüfung der Ergebnisqualität des entwickelten Systems in Bezug auf die Strukturierung eines Volltextes in reduzierte Stichpunkte. Dazu wird eine synthetische Eingabe eines Skillfeldes einer \emph{Bedarfsmeldung} erstellt. Aus dieser wird manuell die wichtigsten Punkte auf Basis der Erkenntnisse aus Kapitel \ref{chap:erwartungshaltung} herausgearbeitet. Dieses dient als Erwartungshaltung, zu dem das System annäherungsweise gelangen soll. Zum semantischen Ähnlichkeitsvergleich wird \emph{Cosine-Similarity} verwendet. Dabei werden die Stichpunkte des Systems und der Erwartungshaltung vektorisiert und durch die Berechnung des \emph{Cosine-Similarity} ein Ähnlichkeitsscoring zwischen 0 und 1 ermittelt. Dabei spiegelt der Wert 0 eine niedrige und 1 eine hohe Ähnlichkeit wider. Das Ziel ist es die Schrittweise Anpassung der Parameter, den Ähnlichkeitswert näher zu 1 zu bringen. Bei jedem Durchlauf des Systems wird die Durchlaufzeit gemessen, um Indikatoren für eine Längere Laufzeit zu ermitteln.
\paragraph{Word Embedding}\mbox{}\\
\emph{Word Embedding} sind Vektordarstellungen eines Wortes, die durch Training eines neuronalen Netzes auf einem großen Korpus gewonnen werden \cite{sitikhu2019comparison}. Sie finden häufig Anwendung bei der Klassifikation von Texten anhand semantischer Ähnlichkeit \cite{sitikhu2019comparison}. Word2vec stellt eine der am häufigsten verwendeten Formen von \emph{Word Embedding} dar \cite{sitikhu2019comparison}. Das Word2Vec-Modell nimmt einen Textkorpus als Eingabe und erzeugt Wortvektoren als Ausgabe, die anschließend für die Klassifizierung eines beliebigen anderen Wortes verwendet werden können \cite{sitikhu2019comparison}. Dazu wird der entsprechende Vektorwert ermittelt \cite{sitikhu2019comparison}. Im Rahmen des Experiments wurde ein vortrainiertes \emph{Word Embedding}-Modell namens \emph{ConceptNet Numberbatch} \cite{speer2017conceptnet} verwendet, um Vektoren für den Eingabetext zu erstellen.
\paragraph{Cosine-Similarity}\mbox{}\\
\emph{Cosine-Similarity} misst den Kosinus des Winkels zwischen zwei Vektoren, die auf eine mehrdimensionale Ebene projiziert werden \cite{sitikhu2019comparison}. Es stellt eine weit verbreitete Metrik im Bereich des Information Retrieval \cite{rahutomo2012semantic}. Die Metrik modelliert ein Textdokument als einen Vektor von Begriffen \cite{rahutomo2012semantic}. Die Berechnung des Kosinuswerts zwischen den Vektoren zweier Dokumente erlaubt die Ermittlung der Ähnlichkeit zwischen diesen Dokumenten \cite{rahutomo2012semantic}. Der Grad der Ähnlichkeit zwischen den Vektoren ist ein Indikator für die Relevanz zwischen den Texten \cite{rahutomo2012semantic}.
%Die Cosinus-Ähnlichkeit ist jedoch nicht in der Lage, die semantische Bedeutung des Textes adäquat zu erfassen. 
%Die syntaktische Implementierung der Cosinus-Ähnlichkeitsmessung zwischen zwei Vektoren kann mitunter zu unzuverlässigen Ergebnissen führen. Der Syntaxabgleich ist möglicherweise nicht in der Lage, das Problem der unterschiedlichen semantischen Bedeutung zu lösen. Dies kann zu falschen Ergebnissen und einer Verschlechterung der Leistung des Information Retrieval Systems führen.
\paragraph{Optimierungsmaßnahmen}\label{sec:optimierungsmaßnahmen}\mbox{}\\
Bei der Durchführung der Evaluation werden vier unterschiedliche Parameter innerhalb des Systems Schrittweise angepasst. Nach jeder Anpassung wird geschaut, ob sich die Cosine-Similarity zur Erwartungshaltung verbessert oder verschlechtert. Wenn der höchste Score ermittelt wurde, wird dieser Parameter in das System fest übernommen und der darauffolgende Parameter wird angepasst. Die vier Parameter sind folgende:
\begin{enumerate}
	\item \textbf{Korpusgröße der Schlüsselwortextraktion} \\ Dabei wird die Menge an \emph{Bedarfsmeldungen} als Korpus für die Schlüsselwortextraktion angepasst. Angefangen von nur offenen und eskalierten \emph{Bedarfsmeldungen} werden auch alle bereits geschlossenen \emph{Bedarfsmeldungen} hinzugefügt. Dies erhöht die Wortmenge innerhalb von \emph{TF-IDF} erheblich. Dabei wird evaluiert, ob die Menge innerhalb des Korpus einen positiven Effekt auf die Identifikation der Schlüsselwörter hat oder ob somit das System nur mehr Zeit bei der Ausführung benötigt.
	\item \textbf{Scorethreshold} \\ Dabei wird der Scorethreshold innerhalb von \emph{TF-IDF} zur Ausschließung von Schlüsselwörtern mit geringem Score angepasst. Der Score wird beginnend mit einem niedrigen Wert (nahe 0) getestet und Schrittweise erhöht.
	\item \textbf{POS-Tagging Kombinationen erlauben} \\ Hierbei werden die untypischen Wortartenkombinationen Schrittweise im System erlauben. In jedem Schritt wird eine Kombination aus dem System entfernt, bis keine mehr enthalten ist.
	\item \textbf{Übersetzung beibehalten} \\ Hierbei werden die Übersetzungsschritte entfernt und überprüft wie sich dies auf die Ergebnisqualität auswirkt. Die Übersetzungen sind API-Anfragen, die dafür sorgen können, dass das System länger bei der Durchführung benötigt.
\end{enumerate}
%pareto evaluation --> ziel ist es die pareto ebene zu finden. Einfach aufschreiben. 80 20 prinzip --> ich habe versucht mit 5 stellschrauben und habe eine qualitätsmetrik(zahl 0-1) ich drehe ein qualitätsmerkmal dann verbessert sich zahl. Fixiere die stellschrauben und mache weiter --> bis ich alles durch habe --> optimierende evaluation (linear)
\paragraph{Zeitmessung}\mbox{}\\
Die Zeitmessung spielt in der Hinsicht eine Rolle als, dass langfristig eine Lösung gesucht wird, die \emph{Bedarfsmeldungen} in Echtzeit bearbeiten kann. Für die Zeitmessung wird vor dem Aufruf des ersten und nach dem letzten Schritt im System jeweils ein Zeitstempel angelegt. Dazu wird die Bibliothek \emph{time} verwendet. Die Zeitstempel werden generiert und in Variablen zwischengespeichert. Zum Schluss wird die Differenz aus beiden Zeitstempeln ermittelt, in Sekunden umgerechnet und ausgegeben.\\
\todo{sagen welche hardware ich verwendet habe}
\section{Beschreibung des verwendeten Datensatzes}
In diesem Kapitel wird eine Ausgangslage und Erwartungshaltung konstruiert. Diese werden für die Berechnung der Kosinus-Ähnlichkeit verwendet, um eine Verbesserung der textuellen Ähnlichkeit festzustellen.
\paragraph{Ausgangslage}\mbox{}\\
Die Ausgangslage ist ein synthetischer Datensatz. Dieser wurde aus echten Bedarfsmeldungen abgeleitet. Bei der Erstellung wurde darauf geachtet, dass dieser einer echten \emph{Bedarfsmeldung} ähneln kann. Die Ausgangslage liegt als Volltext vor:\\

\textbf{Aufgabe ist es, beim Aufbau einer Plattform zu unterstützen, die auf Basis von Azure, OpenAI, Java und ReactJS aufgebaut ist. Aktuell (und perspektivisch) haben wir einen Engpass vor allem im Frontend. Hilfe im Backend (Java) wäre aber auch willkommen.\textbackslash r\textbackslash nDas Projekt bietet einiges an Potenzial, d.h. wir erwarten hier noch einige Interessenten für die Plattform. 2 Jahre Erfahrung und Kenntnisse in der Software-Entwicklung mit Java sind erwünscht}\\

Im Volltext sind diverse Zeichen, Formatierungen (\textbackslash r \textbackslash n für Zeilenumbrüche) und Zeitbezogene Daten enthalten.
\paragraph{Erwartungshaltung}\mbox{}\\
Die Erwartungshaltung wurde manuell aus der Ausgangslage angefertigt. Bei der Erstellung wurde beachtet, dass Füllwörter entfernt und wichtige Informationen beibehalten wurden, die in Kapitel \ref{chap:erwartungshaltung} erfasst wurden. Das Ziel ist es annäherungsweise an diese Erwartungshaltung heranzukommen:
\begin{itemize}
	\item Aufbau einer Plattform
	\item Azure, OpenAI, Java und ReactJS
	\item Engpass im Frontend
	\item Hilfe im Backend (Java)
	\item bietet Potenzial
	\item erwarten Interessenten für Plattform.
	\item 2 Jahre Erfahrung in Java
\end{itemize}
\section{Präsentation und Diskussion der Ergebnisse}
Nachfolgend wird beschrieben, welche Resultate bei den einzelnen Anpassungsschritten aus Kapitel \ref{sec:optimierungsmaßnahmen} herausgefunden wurde.
\paragraph{1. Korpusgröße der Schlüsselwortextraktion}\mbox{}\\
Die These ist, dass je mehr Wörter und Daten im Textkorpus für die Schlüsselwörterextraktion enthalten sind, auch bessere Ergebnisse in der Qualität der Schlüsselwörter erfolgt. Diese Annahme beruht auf der Idee, dass durch mehr themenbezogene Dokumente, häufig auftauchende fachliche Wörter enthalten sind und diese dadurch bei der Term Frequency-Berechnung einen höheren Score erhalten und eher als potenziell wichtiges Schlüsselwort erfasst werden.\\

Um diese These zu überprüfen werden die Felder \emph{skills} und \emph{tasks} aus \emph{Bedarfsmeldungen} mit bestimmten Status schrittweise hinzugefügt. Zu Beginn werden lediglich \emph{Bedarfsmeldungen} mit dem Status \emph{offen} als Korpus hinzugefügt. Darauffolgend werden zudem auch \emph{Bedarfsmeldungen} mit dem Status \emph{eskaliert} dem Korpus hinzugefügt. Anschließend wird der Status \emph{Angeboten} und abschließend alle übrig gebliebenen \emph{Bedarfsmeldungen} hinzugefügt.



bis zum erreichen des plateaus wächst der score werden exponentiell mehr weörter benötigt um den score linear darzustellen.


man kann einen annähernd linearen zusammenhang zwischen dem score und anzahl der wörter im halblogarithmischen diagramm erkennen. dies bedeutet dass der score proportional zur exponentiellen anzahl der wörter ist.

%\begin{longtable}{| p{1cm} | p{6cm} | p{3cm} | p{3cm} |}
%		\hline
%		Schritt & Bedarfsmeldungsfelder & Status & Kumulierte Wörteranzahl \\
%		\hline
%		\hline
%		1 & \emph{tasks}-Felder & \emph{offen} & 2394\\
%		\hline
%		2 & \emph{skill}-Felder & \emph{offen} & 2394\\
%		\hline
%		3 & \emph{tasks}-Felder & \emph{geschlossen} & 2394\\
%		\hline
%		4 & \emph{skill}-Felder & \emph{offen} & 2394\\
%		\hline
%		5 &  & & \\
%		\hline
%		6 &  & & \\
%		\hline
%		\caption{Übersicht der Ergebnisse aus Schritt 1}
%		\label{tab:korpus}
%\end{longtable}
\paragraph{2. Scorethreshold}\mbox{}\\
Hierbei ist die These, dass die Schlüsselwörterqualität durch einen Threshold gesteigert wird. Wörter unter dem Threshold werden bei der Schlüsselwörterermittlung entfernt, wodurch Wörter mit einem niedrigen Scoring nicht beachtet werden. Ein niedriger Scoring kann bedeuten, dass ein Wort nur einmal Vorkommt, wodurch es kein Schlüsselwort abbildet.\\

Um diese These zu überprüfen werden Threshold-Werte von 0.0 bis 1.0 in 0.001er Schritten durchlaufen.

\paragraph{3. POS-Tagging Kombinationen erlauben}\mbox{}\\
Die These ist, dass durch die Entfernung von untypischen Wortkombinationen die qualität der Stichpunkte sinkt. % die Informationen aus unterschiedlichen

\paragraph{4. Übersetzung beibehalten}\mbox{}\\
Die These ist, dass ohne Übersetzung ins Englische die Implementierten \emph{NLP}-Ansätze schlechtere Ergebnisse liefern. Die Idee dahinter ist, dass diese mit Englischen Datensätzen trainiert sind und mit deutschen Wörtern eventuell nicht optimal funktionieren.

%\section{Vergleich des Systems mit einem Large Language Model-Ansatz}
%\section{Analyse von Abweichungen, Ähnlichkeiten und Verbesserungspotenzialen des Systems}
\newpage
