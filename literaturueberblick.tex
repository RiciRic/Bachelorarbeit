\chapter{Literaturüberblick}
\label{chap:literaturüberblick}
Das Ziel dieser Arbeit ist die Informationsgewinnung aus semistrukutrierten \emph{Bedarfsmeldungen} für ein Recommender System, das Mitarbeiterempfehlungen innerhalb von \emph{adesso} für ausgewählte Projekte generieren soll. In diesem Kapitel werden die für das Thema notwendigen Grundlagen und bereits erforschten Themengebiete im Kontext von Recommender Systemen und Informationsverarbeitung behandelt, die für das weitere Verständnis der Arbeit notwendig sind. Es wird ein Einblick in die Art und Weise gegeben, wie andere Autoren Information Retrieval und Filtering einsetzen und kombinieren.

\section{Recommender Systems Historie und aktueller Stand der Forschung}
Auch wenn die Erstellung eines Recommender Systems nicht Gegenstand der vorliegenden Ausarbeitung ist, stellt die Nutzung von Information Retrieval und Filtering ein entscheidener Schritt in Richtung eines funktionierenden Recommender Systems dar. Das Verständnis der Funktionsweise eines Recommender Systems sowie dessen Entwicklung in den vergangenen Jahren ist daher für das Verständnis des Teilbereichs dieser Thematik von Nutzen.\\

Recommender Systems existieren bereits seit vielen Jahren. Im Jahr 1992 führten Belkin und Croft eine Analyse und einen Vergleich des Information Retrievals und Filtering durch \cite{dong2022brief}. Das Information Retrieval behandelt dahingehend die grundlegende Technologie der Suchmaschine \cite{dong2022brief}. Das Recommender System basiert hauptsächlich auf der Technologie des Information Filtering. Im selben Jahr präsentierte Goldberg das Tapestry-System, welches das erste System zur Informationsfilterung darstellt, das auf kollaboratives Filtern durch menschliche Bewertung basiert. Die Mehrheit der frühen Empfehlungsmodelle basiert auf kollaborativer Empfehlungen, wobei K-Nearest-Neighbor (KNN)-Modelle eine besondere Rolle einnehmen. Diese Modelle prognostizieren die Nachbarn eines Zielnutzers, indem sie eine Ähnlichkeit zwischen den vorherigen Präferenzen und den Präferenzen der anderen Nutzer berechnen \cite{dong2022brief}. Die Studie von Goldberg inspirierte einige Forscher des Massachusetts Institute of Technology (MIT) und der University of Minnesota (UMN) dazu, einen Nachrichtenempfehlungsdienst mit dem Namen \emph{GroupLens} zu entwickeln. Die Hauptkomponente dieses Dienstes ist ein Modell zur kollaborativen Filterung zwischen Nutzern \cite{dong2022brief}. Das gleichnamige Forschungslabor kann somit als Pionier auf dem Gebiet der Recommender Systems bezeichnet werden. Die dort durchgeführten Forschungen bilden die Grundlage für nachfolgende Musik- und Video-Ähnlichkeitsempfehlungen \cite{dong2022brief}. \\

Recommender Systeme haben in den letzten Jahren verschiedene Definitionen erhalten. Eine dieser Definitionen wird in dem Artikel von Resnick und Varian (1997) sinngemäß so beschrieben, dass ein typisches Recommender System Empfehlungen durch Personen als Eingabe erhält, die das System dann zusammenschließt und an geeignete Empfänger weiterleitet \cite{burke2011recommender}. In einigen Fällen besteht die primäre Transformation in der Zusammenführung, in anderen Fällen liegt die Fähigkeit des Systems darin, gute Übereinstimmungen zwischen Empfehlungsgebern und Empfehlungsempfängern herzustellen \cite{burke2011recommender}. Empfehlungssysteme stellen ein Instrument zur Interaktion mit umfangreichen und vielschichtigen Informationen dar. Sie ermöglichen eine personalisierte Sicht auf diese Informationen, indem sie die für den Nutzer wahrscheinlich relevanten Inhalte aufbereiten \cite{burke2011recommender}. Besonders im Handelsverkehr im Internet sind Recommender Systeme ein häufiger Einsatzgebiet. Dabei werden Recommender Systeme als Werkzeuge zum Suchen und Filtern von Informationen verwendet, die dem Benutzer Vorschläge unterbreiten, die für ihn nützlich sein könnten. Sie sind in einer Vielzahl von Internetanwendungen weit verbreitet und helfen den Nutzern, bessere Entscheidungen bei der Suche nach Nachrichten, Musik, Urlaubsangeboten oder Geldanlagen zu treffen \cite{ricci2014recommender}. Eine spezifisches Recommender System konzentriert sich normalerweise auf eine Art von Themengebiet wie z. B. Filme oder Nachrichten \cite{ricci2014recommender}. Darüber hinaus sind sie zu einem entscheidenden Faktor in der Entscheidungsfindung von Organisationen geworden \cite{chartron2014general}. Unternehmen wie \emph{adesso} bauen immer weiter auf Recommender System unterstützte System auf, um Prozesse zu beschleunigen oder zu vereinfachen.\\

Grundsätzlich können die Methoden in vier Typen unterteilt werden:
\begin{itemize}
	\item collaborative Filtering-based (kollaborative Empfehlungssysteme)
	\item content-based (inhaltsbasierte Empfehlungssysteme)
	\item knowledge-based (wissensbasiert Empfehlungssysteme)
	\item hybrid (hybride Empfehlungssysteme)
\end{itemize}
Jede Empfehlungsmethode hat ihre Vorteile und Grenzen \cite{lu2020recommender}. Insbesondere das inhaltsbasierte Empfehlungssystem bring eine hohe Relevanz für das Mitarbeiterempfehlungssystem. Die Grundprinzipien inhaltsbasierter Empfehlungssysteme sind zum einen die Analyse der Beschreibung der von einem bestimmten Benutzer bevorzugten \emph{Items}, um die gemeinsamen Hauptattribute (Präferenzen) zu identifizieren, die diese \emph{Items} unterscheiden. Diese Präferenzen werden in einem \emph{Benutzerprofil} gespeichert \cite{lu2020recommender}. Zusätzlich werden die Eigenschaften jedes \emph{Items} mit dem \emph{Benutzerprofil} verglichen, so dass nur \emph{Items} empfohlen werden, die eine hohe Ähnlichkeit mit dem \emph{Benutzerprofil} aufweisen \cite{lu2020recommender}. Bei der Idee der Mitarbeiterempfehlung kann also die \emph{Bedarfsmeldung} mit den benötigten Projektskills und Anforderung als \emph{Benutzerprofil} angesehen werden. Die Mitarbeiterprofile sind dabei die \emph{Items}. Die Attribute werden verglichen (Skills der Mitarbeiter mit den Skills und Anforderungen der \emph{Bedarfsmeldung}) und ähnliche \emph{Items} werden vorgeschlagen. Mit Hilfe traditioneller Methoden des Information Retrievals, wie z.B. dem Kosinus-Ähnlichkeitsmaß, werden dann Empfehlungen generiert \cite{lu2020recommender}. Darüber hinaus generieren sie Empfehlungen mit Hilfe von statistischen und maschinelle Lernverfahren, die in der Lage sind, Nutzerinteressen aus historischen Nutzerdaten zu lernen \cite{lu2020recommender}.
\section{Verwandte Arbeiten}
%\label{sec:forschung-und-ansätze}
Es gibt eine Reihe an verwandten Arbeiten die sich mit unterschiedlichen Aspekten des Staffing Prozesses und der Nutzung von Information Retrieval und Filtering zur Informationsgewinnung beschäftigen. Dennoch beschäftigt sich keine Arbeit mit dem spezifischen Problem der Informationsgewinnung aus \emph{Bedarfsmeldungen}.

\subsection{kp wie ich es nenne}

Im ersten Paper beschreiben die Autoren einen Ansatz zur Ableitung von Unternehmensdaten und digitalen Fußabdrücken von Mitarbeitern. Mit Hilfe eines Big-Data-Workflows, der die Komponenten Information Retrieval und Suche, Datenfusion, Matrixvervollständigung und ordinale Regression nutzt, können Informationen zur Expertise automatisch zusammengeführt und für die Nutzung durch Experten aufbereitet werden. Das System soll Fähigkeiten, Talente und Fachwissens der Mitarbeiter in einem breiten Bereich wie cloud computing oder cybersecurity einschätzen. Beim Ansatz des Information Retrieval und -fusion wird eine Liste von Suchbegriffen erstellt, die sich auf das breite Fachgebiet der Mitarbeiter beziehen. Die Suche wird nach jedem dieser Abfragebegriffe durchgeführt, um Zusammenhänge zwischen Mitarbeiter und Datenquellen zu finden. Die verschiedenen Zusammenhänge werden miteinander verschmolzen, gewichtet und nach der Abfrage sortiert. Die Mitarbeiter werden nach Daten gewichtet und bewertet, um einen einzigen Wert (sehr niedrig, niedrig, moderat, etwas, begrenzt) für ihr Fachwissen in diesem breiten Bereich zu erhalten.\cite{horesh2016information}\\


%\subsection{Recommender System}
%Content based recommendation für filme über genres \cite{reddy2019content}\\

\subsection{Information Filtering}
Diese Arbeit befasst sich unter anderem mit dem Aspekt des content based Information Filtering. Das Ziel dabei ist es Informationen auf die Interessengebiete der Benutzer zu reduzieren. Dazu werden nicht relevante Dokumente aus einem Strom von Informationen entfernt, sodass dem Anwendern nur relevante Dokumente präsentiert werden. Ein Teil der Arbeit beschäftigt sich mit der Informationsfilterung und mögliche Filterungsvarianten werden vorgestellt. Die Arbeit konzentriert sich auf die inhaltsbasierte Filterung von Textdokumenten und identifiziert Informationsfilterung als einen Spezialfall der Textklassifikation. Dazu wird ein Überblick über gängige Methoden des Information Filtering gegeben und ihre Leistung evaluiert.
\cite{lanquillon2001enhancing}

\subsection{Vorverarbeitung}
Diese Arbeit zeigt Wege und Schritte zur Aufbereitung von Datensätzen auf. Die Arbeit umfasst Data-Mining Vorverarbeitungsmethoden, um die Qualität der Daten zu verbessern. Diese weisen wichtiger Schritte auf, um die Effizienz in der Datensammlung zu verbessern \cite{alasadi2017review}. (Nicht sicher ob ich das drin lassen soll)\\

In diesem Beitrag wird der Teil des Anforderungsspezifikationsprozesses diskutiert, der zwischen der textuellen Anforderungsdefinition und den dazugehörigen Diagrammen der Anforderungsspezifikation liegt. Es wird die These aufgestellt, dass die Erstellung einer textuellen Anforderungsbeschreibung, welche das Verständnis des Analysten für das Problem darstellt, die Effizienz der Anforderungsvalidierung durch den Benutzer verbessert. Die vorliegende Idee ist aus dem Problem entstanden, dass Software-Entwickler nicht immer über die erforderlichen Kenntnisse in den fachlichen Abläufen der Themengebiete verfügen, die für die Erstellung der Software relevant sind. Im Rahmen der Anforderungsdefinition erfolgt eine textuelle Verfeinerung, welche als Anforderungsbeschreibung bezeichnet werden kann. Bei der Arbeit mit dem unterstützten Werkzeug \emph{Tessi} ist der Analytiker durch die genannten Vorgaben gezwungen, Anforderungen zu vervollständigen und zu erklären sowie die Rollen der Wörter im Text im Sinne der objektorientierten Analyse zu spezifizieren. Im Rahmen der Vorverarbeitung erfolgt eine Transformation der Requirements durch Templates.\cite{kroha2000preprocessing}

\subsection{Hybride Ansätze}
In der vorliegenden Untersuchung wird die Entwicklung von Kombinationen im Bereich des Information Retrievals analysiert. Dabei werden sowohl experimentelle Ergebnisse als auch die Retrieval-Modelle, die als formale Rahmen für die Kombination vorgeschlagen wurden, berücksichtigt. Es wird aufgezeigt, dass Kombinationsansätze für die Informationssuche als Kombination der Ergebnisse mehrerer Klassifikatoren auf der Grundlage einer oder mehrerer Darstellungen modelliert werden können. Zudem wird dargelegt, dass dieses einfache Modell Erklärungen für viele der experimentellen Ergebnisse liefern kann.\cite{croft2000combining}\\

Die vorliegende Arbeit kombiniert drei Ansätze des Information Retrievals mit dem Ziel, relevante Informationen aus Produktreviews zu extrahieren. Der Ansatz TF-IDF wird mit einem sogenannten CLASSIFIER Model kombiniert. Das Klassifikationsmodell verarbeitet drei Eingaben der Modelle LSTM, VADER und TF-IDF. Die Werte dieser Eingaben liegen im Bereich von [0,1]. Die Ausgabe des Klassifikationsmodells ist binär und gibt eine Vorhersage des vollständigen Textes der Modelleingabe aus (positiv oder negativ).\cite{chiny2021lstm}\\

Diese Arbeit befasst sich mit der Filterung von Fake news. In diesem Beitrag werden hybride Verfahren zur Gewinnung von Merkmalen untersucht, die in dem Gebiet noch nicht gründlich erforscht wurden. Die Anwendung von Hybridsystemen hat sich in einer Vielzahl von Anwendungsbereichen als nützlich erwiesen und zeigen eine Tendenz, die Fehlerquote zu reduzieren, indem sie Techniken wie TF-IDF und N-Grams verwenden.\cite{suhasini2021hybrid}\\

Im Rahmen dieser Studie wurde ein hybrider Algorithmus zur Extraktion von Schlüsselwörtern und Kosinusähnlichkeit zur Verbesserung der Satzkohäsion bei der Textzusammenfassung vorgeschlagen. Die vorgeschlagene Methode basiert auf einer Komprimierung von 50 \%, 30 \% und 20 \%, um Kandidaten für die Zusammenfassung zu erstellen. Die Auswertung des Ergebnisses mittels t-Test zeigt, dass die vorgeschlagene Methode den Kohäsionsgrad signifikant erhöht.
Der Ablauf umfasst die Analyse eines Dokuments mithilfe eines Extraktionsalgorithmus sowie die Berechnung der TF/IDF-Werte für jeden Begriff. Anschließend werden alle TF/IDF-Werte für jeden Satz summiert. Im nächsten Schritt werden alle Sätze anhand der Summe von TF/IDF eingestuft. Das Kompressionsverhältnis bestimmt die Position des Satzrangs. In dieser Studie wird eine Kompression von 50 \% verwendet, was bedeutet, dass die Satzzusammenfassung um 50 \% des Originaltextes gekürzt wird. Nach der Auswahl des Satzes wird dessen Berechnung durchgeführt. Die Ähnlichkeit wird mit der Cosinus-Ähnlichkeitsmethode berechnet. Anschließend werden alle Sätze anhand ihrer Cosinus-Ähnlichkeit von der höchsten zur niedrigsten sortiert. Der resultierende Text mit neuer Satzanordnung stellt die finale Zusammenfassung dar.\cite{darmawan2015hybrid}\\

\subsection{Pipeline}
In dieser Arbeit wird eine Pipeline entwickelt, die die N-Gramm-Analyse verwendet, um Schlagwörter aus einem Text zu extrahieren und mit verschiedenen Ansätzen von Word-Clouds zu visualisieren.\cite{pirk2019implementierung}\\

Die vorliegende Arbeit präsentiert eine Anleitung zur Erstellung einer Pipeline mit Python und TF-IDF. Darüber hinaus wird die Relevanz von TF-IDF als Vorverarbeitung beim maschinellen Lernen erörtert. Im Vergleich zur rohen Termhäufigkeit weist TF-IDF in der Regel einen höheren Vorhersagewert auf. Die Gewichtung von Themenwörtern wird erhöht, um die Bedeutung von Wörtern zu erhöhen, während die Gewichtung von hochfrequenten Funktionswörtern verringert wird. Es werden Verfahren zur Vorverarbeitung von Texten vorgestellt, die eine Umformung in die gewünschte Darstellungsform ermöglichen. Zudem werden Methoden zur Interpretation der Ergebnisse des TF-IDF-Verfahrens erörtert.\cite{lavin2019analyzing}\\

Die Verarbeitung natürlicher Sprache wirft insbesondere bei der Analyse unüblicher Sprachen wie Griechisch Schwierigkeiten auf. In diesem Beitrag wird ein maschineller Lernansatz für die Bereiche Part-of-Speech-Tagging und Named-Entity-Recognition für die griechische Sprache unter Verwendung von spaCy erarbeitet und evaluiert. \cite{partalidou2019design}\\

spam-filter (Empfinde das Thema eventuell als zu unpassend)\\
-Überblick über verfügbare Methoden, Herausforderungen und zukünftige Forschungsrichtungen im Bereich der Spam-Erkennung, Filterung und Eindämmung von SMS-Spam. Dabei werden auch Methodiken der keyword frequency ratio und Herunterbrechung auf keyword components behandelt \cite{shafi2017review}\\

----
%In diesem Beitrag werden Studien zu Technologien vorgestellt, die für die Suche und das Abrufen von Informationen im Web nützlich sind. Es wird aufgezeigt, dass Information Retrieval und Ranking im Web-Kontext anders Funktioniert als in einer statischen Datenbank. \cite{kobayashi2000information}\\

%konzeptbasiertes recruiting --> neuer Ansatz

\section{Definitionen und Konzepte: Information Retrieval, Data-Mining}
\label{sec:definitionen-konzepte}
\todo{Lieber vor dem Kapitel Verwandte Arbeiten packen}

Diese Arbeit beschreibt den Unterschied zwischen Information Filtering und Information Retrieval\cite{belkin1992information}

%\section{Relevante Methoden und Techniken im Bereich Information Retrieval und Data-Mining}
%\label{sec:relevante-methoden}
\newpage
g
\newpage





