\chapter{Analyse der Techniken des Information Retrieval und Data-Mining}
\label{chap:staffingadvisor}

\section{Beschreibung der untersuchten Techniken und Ansätze}

\subsection{TF-IDF}
Im Rahmen der Textanalyse wird die TF-IDF-Technik angewendet, welche die häufigsten Begriffe eliminiert und lediglich die relevantesten Begriffe aus einem Textkorpus extrahiert \cite{bafna2016document}. Die TF-IDF-Methode dient der Ermittlung der Häufigkeit von Wörtern in einem bestimmten Dokument im Vergleich zum Anteil dieses Wortes im gesamten Dokumenten \cite{ramos2003using}. Die Berechnung erlaubt eine Einschätzung der Relevanz eines bestimmten Wortes in einem bestimmten Dokument \cite{ramos2003using}. Die Grundidee des Ansatzes besteht darin, dass Wörter, die in einem einzigen Dokument oder in einer kleinen Gruppe von Dokumenten häufig vorkommen, tendenziell höhere TF-IDF-Werte aufweisen als häufig vorkommende Wörter wie Artikel und Präpositionen \cite{ramos2003using}. TF-IDF stellt ein effizientes Verfahren zum Abgleich von Wörtern in einer Anfrage mit Dokumenten dar \cite{ramos2003using}. Bei Eingabe einer Abfrage zu einem bestimmten Thema durch einen Benutzer kann TF-IDF relevante Informationen zu dieser Abfrage in Dokumenten finden \cite{ramos2003using}. In Bezug auf die Bedarfsmeldungen besteht somit die Möglichkeit, Wörter aus einer Bedarfsmeldung mit anderen Bedarfsmeldungen zu vergleichen und die Häufigkeit ihrer Verwendung zu ermitteln, um somit potenzielle Schlüsselwörter zu ermitteln.\\

Trotz der Stärken von TF-IDF, sind auch seine Grenzen zu berücksichtigen. In Bezug auf Synonyme ist zu beachten, dass TF-IDF nicht auf die Beziehung zwischen den Wörtern eingeht. Des Weiteren werden unterschiedliche Schreibweisen von Wörtern nicht berücksichtigt, was dazu führen kann, dass Wörter fälschlicherweise als nicht so häufig auftauchend deklariert werden, obwohl sie mit leicht abgewandelter Schreibweise häufiger vorkommen.
\subsection{Text-Ranking-Algorithmen}
Text-Ranking-Algorithmen: Text-Ranking-Algorithmen wie TextRank oder YAKE (Yet Another Keyword Extractor) verwenden graphenbasierte Methoden, um Schlüsselwörter in einem Text zu identifizieren. Die Algorithmen bewerten die Wichtigkeit von Wörtern basierend auf ihrer Verbindung zu anderen Wörtern im Text und extrahieren Schlüsselwörter entsprechend ihrer Rangfolge.\\ \cite{mihalcea2004textrank}\cite{zhang2020empirical}\cite{pay2019ensemble}\\

Ein graphenbasierter Rangordnungsalgorithmus stellt eine Möglichkeit dar, die Wichtigkeit eines Knotens innerhalb eines Graphen zu bestimmen. Dabei werden globale Informationen berücksichtigt, die rekursiv aus dem gesamten Graphen berechnet werden. Im Gegensatz zu anderen Methoden, die sich lediglich auf lokale, knotenspezifische Informationen stützen, ermöglicht dies eine objektivere Bewertung.\cite{mihalcea2004textrank}

\subsection{N-Gramm}
N-Gramme sind Folgen von Zeichen oder Wörtern, die aus einem Text extrahiert werden. N-Gramme lassen sich in zwei Kategorien unterteilen: i) zeichenbasiert und ii) wortbasiert. Ein Zeichen-N-Gramm bezeichnet eine Folge von n aufeinanderfolgenden Zeichen, die aus einem Wort extrahiert werden. Die Hauptmotivation hinter diesem Ansatz besteht darin, dass ähnliche Wörter einen hohen Anteil an N-Grammen gemeinsam haben werden. In der Regel umfasst ein N-Gramm lediglich die am häufigsten auftretenden Wortpaare und verwendet einen Backoff-Mechanismus, um die Wahrscheinlichkeit zu berechnen, die bei der Suche nach dem gewünschten Wortpaar nicht erfolgreich war. \cite{majumder2002n} Die Analyse von N-Grammen erlaubt die Identifikation häufig vorkommender Phrasen oder Begriffe, die als potenzielle Schlüsselwörter bezeichnet werden können.

\subsection{POS-Tagging}
%Part-of-Speech (POS) Tagging: POS-Tagging wird genutzt, um die grammatischen Kategorien von Wörtern in einem Text zu bestimmen. Durch die Berücksichtigung von Wörtern mit bestimmten POS-Tags wie Substantiven oder Adjektiven können relevante Schlüsselwörter extrahiert werden.\\ \cite{kumawat2015pos}\cite{nakagawa2007hybrid}\\

Die Katalogisierung von Wortarten (POS) bezeichnet einen Prozess, bei dem jedem einzelnen Wort eines Satzes ein Wortart-Tag oder ein anderes philologisches Klassenzeichen zugeordnet wird. Die Vorverarbeitungsaufgabe des Taggings von Sprachbestandteilen stellt einen essenziellen Schritt in der Verarbeitung natürlicher Sprache dar. Die Zuordnung von Wortarten stellt eine grundlegende Aufgabe bei der Verarbeitung natürlicher Sprache dar. Die Erstellung erfolgt unter Zuhilfenahme linguistischer Theorien, zufälliger Muster sowie einer Kombination aus beidem. Ein Part-of-Speech-Tagger (POS-Tagger) ist definiert als ein Teil einer Software, der jedem Wort einer Sprache, das er liest, eine Wortart zuordnet. Die Ansätze des POS-Tagging lassen sich in drei Kategorien unterteilen: regelbasiertes Tagging, statistisches Tagging und hybrides Tagging. Im Rahmen der Zuweisung von POS-Tags zu Wörtern im regelbasierten POS-System erfolgt die Verwendung einer Reihe von handgeschriebenen Regeln in Kombination mit Kontextinformationen. Der Nachteil dieses Systems besteht darin, dass es nicht funktioniert, wenn der Text nicht bekannt ist. Das Problem besteht darin, dass das System nicht in der Lage ist, den passenden Text vorherzusagen. Um eine höhere Effizienz und Genauigkeit in diesem System zu erreichen, ist es daher empfehlenswert, einen umfassenden Satz von handkodierten Regeln zu verwenden. Die Häufigkeit und Wahrscheinlichkeit sind in den statistischen Ansatz einbezogen. Der grundlegende statistische Ansatz basiert auf der am häufigsten verwendeten Markierung für ein bestimmtes Wort in den annotierten Trainingsdaten. Diese Information wird auch zur Markierung dieses Wortes im unannotierten Text verwendet.\cite{kumawat2015pos}

\subsection{Named Entity Recognition}
Named Entity Recognition (NER) \cite{mansouri2008named} \cite{nadeau2007survey}\cite{partalidou2019design}\\

\subsection{Regelbasierte Ansätze}
Regelbasierte Ansätze: Regelbasierte Ansätze verwenden vordefinierte Regeln oder Muster, um Schlüsselwörter zu identifizieren. Dies kann beispielsweise das Extrahieren von Wörtern sein, die häufig im Text vorkommen oder bestimmten Mustern entsprechen.\\

\subsection{Hybride Ansätze}
Hybride Ansätze: Hybride Ansätze kombinieren verschiedene Methoden und Techniken, um eine genauere Extraktion von Schlüsselwörtern zu ermöglichen. (Z.B. Kombination aus TF-IDF-Gewichtung und Text-Ranking-Algorithmen verwendet).\cite{darmawan2015hybrid} \\

\subsection{Data-Mining}
Data-Mining: \cite{jun2001review}\cite{jain2013data}

\subsection{preprocessing}
preprocessing: \cite{garcia2016big}

\subsection{data-fusion}
data-fusion: \cite{famili1997data} \cite{frank2005comparing} \cite{bohne2013data}
\newpage
g
\newpage
g
\newpage
g
\newpage

\section{Bewertung und Auswahl der besten Ansätze für die Extraktion relevanter Inhalte aus Bedarfsmeldungen}

\newpage
g
\newpage